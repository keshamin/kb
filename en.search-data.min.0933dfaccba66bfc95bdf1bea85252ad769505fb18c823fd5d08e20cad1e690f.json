[{"id":0,"href":"/articles/mle/ml-project-lifecycle/","title":"ML Project Lifecycle","section":"Machine Learning Engineering","content":"ML Project Lifecycle #  Scoping Stage #   Data Stage #   Modeling Stage #   Deployment Stage #   The slides on this page are copied from \u0026ldquo;Introduction to Machine Learning in Production\u0026rdquo; course by DeepLearning.ai for educational purposes.  "},{"id":1,"href":"/articles/mle/deployment/","title":"Model Deployment","section":"Machine Learning Engineering","content":"Model Deployment #  Key Challenges #  ML/Statistics Issues #    Data Drift: Input data evolved and a trained model does not interpret it properly anymore\n  Concept Drift: The \u0026ldquo;rules\u0026rdquo; of taking the decision evolved\n   Software Engineering Issues #   Realtime or Batch Cloud or Edge Resources Requirements Latency/Throughput requirements Logging Security and Privacy    Common Deployment Cases #   New product Automate/assist with manual task Replace previous ML system  Deployment modes #   Shadow mode  ML system works in parallel with current solution (manual or previous automated system) ML system\u0026rsquo;s decisions are not taken into account at this point Monitoring system compares results from both systems to estimate accuracy and probably collect more training data   Canary deployment  ML system works in parallel with current solution New system handles a small portion of traffic, e.g. 5% If there\u0026rsquo;s no degradation, the portion is gradually increased   Blue/Green Deployment  ML system works in parallel with current solution At some point a router in front of both systems switches all the traffic to the new system In case of degradation, the rollback is easy    Degree of Automation #   mermaid.initialize({ \"flowchart\": { \"useMaxWidth\":true }, \"theme\": \"default\" } ) flowchart LR HO[/Human Only/] SM[/Shadow Mode/] AA[/AI Assistance/] PA[/Partial Automation/] FA[/Full Automation/] HO---SM---AA---PA---FA \u0026ldquo;Human in the loop\u0026rdquo; deployments:\n AI Assistance: ML System highlights interesting input, but the decision is still taken by human Partial Automation: the decisions are taken by the ML System, but if it is not sure, it forwards the request to human. The approach if very useful to collect more training data when the accuracy is not good enough.  Monitoring #  To build a monitoring dashboard:\n Brainstorm the things that could go wrong Define the metrics that would reflect these problems  It is OK to start with a big number of metrics and remove some of them as you understand which are not representative.  Examples of Metrics #  Software Metrics #   Memory Compute Latency Throughput Server Load   Input Metrics #   Number of missing values Avg input audio length/volume Avg image brightness   Output Metrics #   Average output value Number of NULLs in output Number of times user retries the same request Number of times user refuse to use the system    "},{"id":2,"href":"/articles/mle/","title":"Machine Learning Engineering","section":"Articles","content":"  ML Project Lifecycle  Typical stages of ML Project from scope definition to production.   Model Deployment  Introduction to Model Deployment issue.   "}]