<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MinII KB</title><link>/</link><description>Recent content on MinII KB</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 25 Jul 2022 12:41:36 +0300</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml"/><item><title>ML Pipelines</title><link>/articles/mle/ml_pipelines/</link><pubDate>Tue, 01 Mar 2022 15:40:36 +0300</pubDate><guid>/articles/mle/ml_pipelines/</guid><description>ML Pipelines # Pipeline Orchestrators: infrastructure for automating, monitoring and maintaining model training and deployment.
Examples: Airflow, Argo, Celery, Luigi, KubeFlow.
TensorFlow Extended (TFX) # Open-source end-to-end platform for deploying production ML pipelines.</description></item><item><title>Scoping Stage</title><link>/articles/mle/lifecycle/scoping/</link><pubDate>Fri, 25 Feb 2022 16:48:37 +0300</pubDate><guid>/articles/mle/lifecycle/scoping/</guid><description>Scoping Stage # Always separate a business problem from a technical solution.
Scoping Process: mermaid.initialize({ "flowchart": { "useMaxWidth":true }, "theme": "default" } ) flowchart TD BP(Brainstorm business problems) AIS(Brainstorm AI solutions) ASS(Assess the feasibility and value) MIL(Determine milestones and budget) BP -- AIS AIS -- ASS ASS -- MIL Milestones &amp;amp; Resourcing # Key specifications:
ML metrics (accuracy, precision/recall, &amp;hellip;) Software metrics (latency, throughput, &amp;hellip;) Business metrics (revenue, &amp;hellip;) Resources needed (data, personnel, help from other teams, &amp;hellip;) Timeline If unsure, consider benchmarking to other projects, or building a PoC first.</description></item><item><title>Data Stage</title><link>/articles/mle/lifecycle/data/</link><pubDate>Fri, 25 Feb 2022 11:50:54 +0300</pubDate><guid>/articles/mle/lifecycle/data/</guid><description>Data Stage # Types of Datasets # Small Data vs. Big Data: generally, the threshold is &amp;ldquo;can a small team examine every single example in a reasonable time?&amp;rdquo;.
Small Data
Every record can be manually examined Humans can label data Clean (true and consistent) labels are critical If the labels are inconsistent, it may be more worthy to fix that instead of collecting new data and overcomplicate a model Big Data</description></item><item><title>Modeling Stage</title><link>/articles/mle/lifecycle/modeling/</link><pubDate>Thu, 24 Feb 2022 13:29:29 +0300</pubDate><guid>/articles/mle/lifecycle/modeling/</guid><description>Modeling # AI system = Code + Data Approaches to modeling
Model-centric: improve the algorithm Data-centric: improve the data quality Training Cycle # mermaid.initialize({ "flowchart": { "useMaxWidth":true }, "theme": "default" } ) flowchart LR MHD(Model \n + Hyperparameters \n + Data) TR(Training) EA(Error Analysis) MHD -- TR TR -- EA EA -- MHD Why Low Average Error isn&amp;rsquo;t Good Enough # Typical ML model challenges:</description></item><item><title>Deployment Stage</title><link>/articles/mle/lifecycle/deployment/</link><pubDate>Tue, 22 Feb 2022 15:55:39 +0300</pubDate><guid>/articles/mle/lifecycle/deployment/</guid><description>Model Deployment # Key Challenges # ML/Statistics Issues # Data Drift: Input data evolved and a trained model does not interpret it properly anymore
Concept Drift: The &amp;ldquo;rules&amp;rdquo; of taking the decision evolved
Software Engineering Issues # Realtime or Batch Cloud or Edge Resources Requirements Latency/Throughput requirements Logging Security and Privacy Common Deployment Cases # New product Automate/assist with manual task Replace previous ML system Deployment modes # Shadow mode ML system works in parallel with current solution (manual or previous automated system) ML system&amp;rsquo;s decisions are not taken into account at this point Monitoring system compares results from both systems to estimate accuracy and probably collect more training data Canary deployment ML system works in parallel with current solution New system handles a small portion of traffic, e.</description></item><item><title>Yandex Cloud</title><link>/articles/yandex/</link><pubDate>Mon, 25 Jul 2022 12:41:36 +0300</pubDate><guid>/articles/yandex/</guid><description>Yandex Cloud # Resource Structure in Yandex Cloud # As a rule:
1 cloud == 1 company 1 catalog == 1 project Resource Manager is responsible for organising resources in a structure and assigning permissions.
There are 2 types of roles:
primitive predefined roles: global roles through all the services viewer editor admin service roles: granular roles per each single service fygbyvghcgh Roles are inherited: editor on a Cloud can manage resources in any catalog of the Cloud editor on a Catalog can manage only the resources withing that Catalog Users # There are 3 types of users:</description></item><item><title>MLE Path</title><link>/articles/mle/mle_path/</link><pubDate>Mon, 28 Mar 2022 11:34:00 +0300</pubDate><guid>/articles/mle/mle_path/</guid><description/></item><item><title>Storage</title><link>/articles/mle/data/storage/</link><pubDate>Tue, 22 Mar 2022 13:14:59 +0300</pubDate><guid>/articles/mle/data/storage/</guid><description>Data Storage # Feature Store # Feature store is a central repository for storing documented, curated and access-controlled features.
Features store enables the team to re-use shared features to avoid redundant work.
Key points:
managing feature data from a single person to an enterprise Scalable and performant access to features for training and serving provide consistent and point-in-time correct access enable discovery, documentation and insights Offline feature procesing:</description></item><item><title>Schema Development</title><link>/articles/mle/data/schema/</link><pubDate>Tue, 22 Mar 2022 12:33:40 +0300</pubDate><guid>/articles/mle/data/schema/</guid><description>Schema Development # Schema:
Feature name Data type Required or optional Valency (for multivalue features) Domain or range Default value Schema Environment # Schema Environment means customizing schema basing on the current environment.
Example: remove label column from serving environment.</description></item><item><title>Lineage and Provenance</title><link>/articles/mle/data/lineage/</link><pubDate>Mon, 21 Mar 2022 14:37:37 +0300</pubDate><guid>/articles/mle/data/lineage/</guid><description>Data Lineage and Provenance # To keep track on the data flow Metadata Store is used. It logs information about executions and artifacts.
For example, this is a high-level architecture of TensorFlow ML Metadata (MLMD):</description></item><item><title>TensorFlow Transform</title><link>/articles/mle/tensorflow/transform/</link><pubDate>Tue, 15 Mar 2022 13:40:36 +0300</pubDate><guid>/articles/mle/tensorflow/transform/</guid><description>TensorFlow Transform # ExampleGen splits dataset StatisticsGen calculates statistics per feature SchemaGen infers the types of features ExampleValidator checks for data anomalies Transform performs feature engineering Transform Inputs
Data Schema Transform Outputs
Transformed Data Transform Graph The result transform graph (tf.Graph) holds all necessary constants and transformations. The same chain of transformations can be easily applied at serving time.
Analizers Framework # Analizers:</description></item></channel></rss>